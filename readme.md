<p align="center">
<img src="https://i.imgur.com/WmP38jg.png"  > 
</p>
<p align="center">
<a href="https://matrix.to/#/#arguflow-general:matrix.zerodao.gg">
    <img src="https://img.shields.io/badge/matrix-join-purple?style=flat&logo=matrix&logocolor=white" />
</a>

</p>


Critical times call for critical thinkers to create the decentralized AI Knowledge Graph — a crowdsourced hive mind dataset for ChatGPT to recommend arguments and evolve tree-of-thought reasoning on a topic.



 Chrome Extension - cite maker, flow with timer, editor, Colab Research Sidebar

Colab Research Sidebar - see if anyone else has ever tagged this article  and put in shared hive mind. Highlight keywords as the first step before underlining. 

[ChatGPT 4.0 Plugin](https://github.com/openai/chatgpt-retrieval-plugin) - write extensions per card, generate keywords before reading article to help skim, write response to card using vector search of cards read in round, explain a chain-of-though reasoning to summarize topic as public service of debaters

Crowdsourced Research - github shows people iterate faster and go deeper, deduplication, and card video games show cards can have scores and answer others

Public service of best researched ranked on a public issue,  competition to get likes for discovering a quote you are eager to share

News feed - latest cards cut, speeches, videos

Word Count Format - no need to read fast if you can just have the word count add up to 2000 per speech and read tags slowly, while they focus on reading card's internal warrants 

Online format - online games like overwatch show matchmaking works for practice rounds that take a week of sending speech docs 2000/1200 words and get matched to those who want to go deep into the same Offcases

Debate file format - show only highlighted mode, cards with keyword vectors to find the similar node

Flow - sync timer across room, no need to flow if cards come with flow notes

Round format - 8 speech full rounds instead of speechdocs, record last 3 rebuttals


## ChatGPT Argument Research Dataset as a Service (CARDS)


Debate should be a war of warrants where victories are vectorized as weights — for the AI hive mind to make  decisions based on a crowdsourced tree-of-thought which weighs the best arguments from many perspectives. Group represenation centralized in elected human minds cannot have access to all the information and exclusionary bias.  AI is inevitable, so it is necessary to have public safety testing in a community research lab where users can train these AI models to unlock faster ways to read a long text, stay up to date on a large literature base, and crowdsourced decentralized datasets for AI tree-of-thought reasoning.


ChatGPT 4.0 Plugin  to make debate research available as a service and text classification by vectorized tagline summaries creates a knowledge graph where file names and H1 H2 H3 H4 tags serve as labels and able to map any future articles on a topic to the Argument Node label, like "Impact - Economy War - economic decline is the root cause of war". ChatGPT hive mind agents recommend articles for human researchers working alongside AI to develop a summarized topic outline as a public service. ChatGPT agents monitor for any related articles via google searches for keywords associated with that Argument Topic Model . Some articles will be marked as repetitive or not as useful as higher quality sources, which will prevent students from wasting time on that search result. Crowdsourced automation with AI hive mind agents frees up more time for higher level of complexity to create topic research summaries and argument outlines, similar to what Github does for reusable code.  Training AI to write arguments much better and to summarize and answer better, by finetuning and selecting which cards act as input to answer, in order to accelerate the Singularity when AI beats human debaters. 

_Being_ is Becoming: Whatever things can be, that is what they must become.


Example Use Case: Imagine uploading several academic PDFs about a topic like neural net models, then the app finds the citations full text and creates topic model and keyword summaries, then it recursively searches the secondary papers' citations and monitors that literature base and stores highlights. Similar apps that show this is needed are  [Obsidian](https://obsidian.md/) and [SciSpace](https://typeset.io/questions/gptq-vs-awq-vs-gguf-which-is-better-sv0i4q0ha8).




Example API to helps researchers discover related keywords to search for in the literature base:

```

{"word":"alterity","similar":"['otherness', 'subjectivity', 'levinas', 'self', 'levinas’s', 'irreducible', 'undecidability', 'singularity', 'ontological', 'transcendence', 'derrida', 'levinasian', 'relationality', 'identity', 'exteriority', 'modernity', 'ethics', 'selfhood', 'transgression', 'poetics', 'seduction', 'finitude', 'ontology', 'dialectics', 'binaries', 'postmodern', 'transcendent', 'blackness', 'subjectivities', 'deconstruction', \"lovecraft's\", \"derrida's\", 'hybridity', 'baudrillard’s', 'negation', 'hostis', 'transcendental', 'stranger', 'oneself', 'constitutive', 'phenomenological', 'radical', 'historicity', 'ethical', 'indigeneity', 'difference', 'post-structuralist', 'nihilism', 'aporia', 'essentialised']"}

{"word":"counterplan","similar":"['counterplans', 'resolutional', 'affirmative', 'kritiks', 'kritik', 'affirmative’s', 'non-topical', 'in-round', 'fiat', 'topicality', 'permutation', 'affs', 'nontopical', 'argument', 'solvency', 'guesstimate', 'conditionality', 'eb-7', 'reviewability', 'competition.”', 'inherency', 'topical', 'paraontology', 'disad', '1ac', 'advocacies', 'arguments', 'affirmatives', 'deontological', 'cybermad', 'rule-consequentialism', 'consequentialism', 'actor”', 'testing”', 'one-voice', '2ac', 'negative’s', 'tournament', 'solt', 'grisez', 'germaneness', 'politeia', 'interjurisdictional', 'purusha', 'disadvantages', 'textually', 'neg', '“laboratory”', 'incapacitates', 'consequentialist', 'weakens', 'aff', 'fsia', '“backpack', 'corporate-tax', 'cispa', '“predictions', 'disadvantage', 'critique’s', 'lre', 'competitive', 'textual', 'nullification', 'harman’s', 'sunnah', 'hatab', 'debater', 'contractarian', 'prong', 'correlationist', '7/9/2018', 'eliminates', 'morales-santana', 'credibility.¶', 'experimentalism', \"rule's\", 'defensible', 'benjamin’s', 'catchphrases', 'evasion', 'debaters', 'fg', 'argument—that', 'statutory', 'pascal’s', 'nuclearmad', 'morality', 'competitors', '9-0', 'reasoned', 'neo-isolationism', 'debate', 'it', 'advan', 'vagueness', 'outweigh', 'proposal', 'text', 'prevention’s', 'lipitor']"}

```

## Reference Docs

#### LLAMA2 

- [llama2 overview](https://www.unite.ai/llama-2-a-deep-dive-into-the-open-source-challenger-to-chatgpt/)
  
- [node-llama-cpp bindings](https://withcatai.github.io/node-llama-cpp/guide/)
- [llama2 finetuned models](https://www.reddit.com/r/LocalLLaMA/wiki/models/#wiki_llama_2_models)
- [Llama2 C++ Backend](https://github.com/ggerganov/llama.cpp)
- [text-generation-webui](https://github.com/oobabooga/text-generation-webui)

- [Fine-tune Llama 2 for text generation on Amazon SageMaker JumpStart](https://aws.amazon.com/blogs/machine-learning/fine-tune-llama-2-for-text-generation-on-amazon-sagemaker-jumpstart/)
- [Fast and cost-effective LLaMA 2 fine-tuning with AWS Trainium](https://aws.amazon.com/blogs/machine-learning/fast-and-cost-effective-llama-2-fine-tuning-with-aws-trainium/)

- [Use Llama 2 with an API on AWS ](https://ai.plainenglish.io/how-to-use-llama-2-with-an-api-on-aws-to-power-your-ai-apps-3e5f93314b54)

#### Topic Vector Models

- [ChatGPT RAG Search Plugin](https://github.com/openai/chatgpt-retrieval-plugin)
- [OpenAI Vectors](https://openai.com/blog/introducing-text-and-code-embeddings)
- [BERTopic](https://github.com/MaartenGr/BERTopic)
- [Autogen AI & Human Colab](https://github.com/microsoft/autogen/blob/main/notebook/agentchat_two_users.ipynb)
- [Tree-of-Thought Prompt](https://github.com/princeton-nlp/tree-of-thought-llm)
- [SetFit Topic Model](https://github.com/huggingface/setfit)
- [Embedding Next Top Model](https://huggingface.co/spaces/mteb/leaderboard), 
[Google Vertex AI ](https://cloud.google.com/vertex-ai/docs/generative-ai/learn-resources)

- [Split Highlight Extract into Sentences](https://github.com/bminixhofer/wtpsplit)

- [Lit2vec visualization](https://github.com/Santosh-Gupta/Lit2Vec)
- [scattertext visualization](https://github.com/JasonKessler/scattertext)
- [HNSW Vector Visualization](https://colab.research.google.com/drive/12L_oJPR-yFDlORpPondsqGNTPVsSsUwi?usp=sharing#scrollTo=QhHqESI-Yc3j)

- [ChatGPT Prompt Over 4000 Word Limit](https://docs.llamaindex.ai/en/stable/examples/low_level/response_synthesis.html)
- [KG Embedding Papers](https://github.com/shaoxiongji/knowledge-graphs/blob/master/papers/KG-embedding.md)